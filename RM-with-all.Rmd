---
title: "Recognition Memory"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include = FALSE}
library(tidyverse)
library(afex)
library(BayesFactor)
library(apa)
knitr::opts_chunk$set(echo = FALSE)
# function to force scientific formatting of numbers (used for large BFs)
changeSciNot <- function(n) {
  output <- format(n, scientific = TRUE, digits = 2) #Transforms the number into scientific notation even if small
  output <- sub("e", "x10^", output) #Replace e with 10^
  output <- sub("\\+0?", "", output) #Remove + symbol and leading zeros on exponent, if > 1
  output <- sub("-0?", "-", output) #Leaves - symbol but removes leading zeros on exponent, if < 1
  output <- paste0(output,"^")
  # output = strsplit(output, "^", fixed = TRUE)
  # output = paste0(output[[1]][1],"^", output[[1]][2], "^")
  output
}

# function to extract and report BFs with error %s
report_BF_and_error <- function(BF_in, sci_not = TRUE, hyp = "alt"){
  
  if (hyp == "alt") {
    BF_notation = "BF~10~ = "
  } else if (hyp == "null") {
    BF_notation = "BF~01~ = "
  }
  
  if (sci_not == TRUE) {
    BF_value = changeSciNot(extractBF(BF_in)$bf) # change to sci notation
  } else {
    BF_value = round(extractBF(BF_in)$bf,2) # otherwise round
  }
  
  paste0(BF_notation, 
         BF_value, 
         " &plusmn; ", 
         round(100*extractBF(BF_in)$error,2), 
         "%")
}
```

# Method

28 subjects were used. Experiment consisted in 3 training phases, followed by a test phase. In training, for a total of 8 blocks, 4 different types of cue1, 4 different types of cue2, and 2 outcomes were presented. The image dispalyed in each type of cue was randomly asigned for each participant. Both phase 1 and 2 comprised 1 blocks, whereas phase 3 consisted on 6 blocks. All blocks were a sequence of 20 trials. In each trial, a cue1 and a cue2 were presented, followed by an outcome. In phase 1, there were 2 types of cue1 (1 and 2) and 2 types of cue2 (5 and 6), thus creating 4 different combinations that were repeated 10 times across the phase. Cue 1 was always paired with outcome 1 and cue 2 was always paired with outcome 2, whereas cues 5 and 6 where paired with each outcome half of the times. In phase 2 there were 2 different types of cue1 (3 and 4) and 2 types of cue2 (7 and 8), thus creating 4 different combinations that were repeated 10 times across the phase. Cue 3 was paired with outcome 1 with a 0.8 contingency, being the rest of trials paired with outcome 2. The opposite was true for cue 4, and cues 7 and 8 where paired with each outcome half of the times. In phase 3, the stimuli combinations from the two previous phases were intermixed. The contingencies between cues and outcomes where maintained as in the previous phases. In this training phase, on each trial, the participants had to predict the probable outcome of the cues presented, and the response given as well as the reaction time (RT) were recorded. Based on the programmed contingencies, an additional measure of accuracy was computed, comparing the most probable outcome (that is, the outcome with a higher contingency with cue1) with the response emitted by the participant.

In test phase, the participants were presented each of the 8 cues twice, together with a similar yet new cue, and where asked to choose what cue they had seen before, as well as rating how sure they were of their response. The rating RT was also recorded. A memory score was computed, taking the rating given to the cue in positive when the response was right, and in negative when it was wrong. A corrected version of this score was also computed in order to clean the noise of errors, taking into account just the ratings of the trials in which the participant chose the right stimulus.

+------------+-------------------------+------------------------+------------+
| Phase 1    | Phase 2                 | Phase 3                | Test       |
+:==========:+:=======================:+:======================:+:==========:+
| AX - O1    | 0.8CW - O1 / 0.2CW - O2 | Phases 1 &2 intermixed | A\         |
|            |                         |                        | B\         |
| AY - O1    | 0.8CZ - O1 / 0.2CZ - O2 |                        | C\         |
|            |                         |                        | D\         |
| BX - O2    | 0.8DW - O2 / 0.2DW - O1 |                        | X\         |
|            |                         |                        | Y\         |
| BY - O2    | 0.8DZ - O2 / 0.2DZ - O1 |                        | W\         |
|            |                         |                        | Z          |
+------------+-------------------------+------------------------+------------+

```{r, include = FALSE}
#create a joint dataframe
#first rename the data there so I doesn't overwritte them
load("UNM02_proc_data.RData")
UNM02_data <- data
UNM02_test_data <- test_data
load("UNM03_proc_data (1).rdata")
UNM03_data <- data
UNM03_test_data <- test_data
#change pNum in UNM03
UNM03_data$pNum <- rep(29:41, each = 160)
UNM03_test_data$pNum <- rep(29:41, each = 16)
#now merge them together
merged_data <- rbind(UNM02_data, UNM03_data)
merged_test_data <- rbind(UNM02_test_data, UNM03_test_data)
```

# Results

## Training phase

As can be seen in the Figure below, the accuracy to the certain cues increased during phase 1, but it seems to decrease again at the start of phase 3, then gradually increasing to reach a value of around 0.85 at the end of training. The accuracy to uncertain cues, although not as better as for the certain groups, increases throughout the training phase, reaching a level of around 0.65 at the end of it.

```{r, include=FALSE}
#create phases dataframes
merged_data <- mutate(merged_data, block_real = rep(1:8, each = 20), .after = block)

#change -99 values for NA
merged_data["prob_response"][merged_data["prob_response"] == -99] <- NA
merged_data["RT"][merged_data["RT"] == -99] <- NA

#prepare data
merged_data <- mutate(merged_data, 
               cue_type = case_when(cue1 == 1 | cue1 == 2 ~ "certain",
  cue1 == 3 | cue1 == 4 ~ "uncertain"))
MA_training <- merged_data %>%
  group_by(phase, cue_type, block_real) %>%
  summarise(mean_accuracy = mean(prob_response, na.rm = TRUE), 
            sd_accuracy = sd(prob_response, na.rm = TRUE)/sqrt(length(prob_response)))
```

```{r}
#plot accuracy
ggplot(MA_training, mapping = aes(x = block_real, y = mean_accuracy, color = cue_type)) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(x= block_real, y = mean_accuracy, ymin = mean_accuracy-sd_accuracy, ymax = mean_accuracy+sd_accuracy), color = "black", width=.1,position=position_dodge(0.05)) +
  facet_grid(cols = vars(phase), space = "free_x", scales = "free_x") + 
  scale_x_continuous(breaks = c(seq (1, 16, 1))) +
  scale_y_continuous(name="Accuracy", limits=c(0.45, 1)) +
  labs(title = "Figure 1", subtitle = "Mean corrected accuracy for the 16 block of the three phases of training")
```

```{r, include = FALSE}
phase1 <- filter(merged_data, phase == 1)
phase2 <- filter(merged_data, phase == 2)
phase3 <- filter(merged_data, phase == 3)

#t test to check >.5
mean_cert <- filter(merged_data, cue_type == "certain") %>%
  group_by(pNum) %>%
   summarise(mean_response = mean(prob_response, na.rm = TRUE))
cert_t <- t.test(mean_cert, mu = .5, alternative = "greater")

mean_uncert <- filter(merged_data, cue_type == "uncertain") %>%
  group_by(pNum) %>%
   summarise(mean_response = mean(prob_response, na.rm = TRUE))
uncert_t <- t.test(mean_cert, mu = .5, alternative = "greater")
```
```{r, include = FALSE}
#t.test for the experiment
mean_exp_phase1 <- phase1 %>%
  group_by(pNum, exp_code) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
exp_p1_t <- t.test(mean_response ~ exp_code, mean_exp_phase1, var.equal = TRUE)
mean_exp_phase2 <- phase2 %>%
  group_by(pNum, exp_code) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
exp_p2_t <- t.test(mean_response ~ exp_code, mean_exp_phase2, var.equal = TRUE)
```
Mean responding throughout the experiment was significantly above chance for both certain and uncertain cues, as confirmed by a one sample t test (Certain: `r apa(cert_t)`, Uncertain: `r apa(uncert_t)`). Also, its worth noting that neither in phase 1 nor phase 2 there were significant differences in responding due to the experiment the data came from (`r apa(exp_p1_t)`; `r apa(exp_p2_t)`)
```{r}
#preapare ANOVA phase 3
exp_response_phase3 <- phase3 %>%
  group_by (exp_code, pNum, block, cue_type) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
exp_response_phase3$exp_code <- factor(exp_response_phase3$exp_code)
exp_response_phase3$block <- factor(exp_response_phase3$block)
exp_response_phase3$cue_type <- factor(exp_response_phase3$cue_type)
exp_response_phase3$pNum <- factor(exp_response_phase3$pNum)

#ANOVA 3 with exp_code
exp_ANOVA_p3_resp <- aov_car(formula = mean_response ~ exp_code + Error(pNum/block*cue_type), data = exp_response_phase3)
exp_bay_ANOVA_p3_resp <- anovaBF(formula = mean_response ~ block*cue_type*exp_code + pNum,
        data = data.frame(exp_response_phase3),
        whichRandom = "pNum")
expxblock_int <- exp_bay_ANOVA_p3_resp [4] / exp_bay_ANOVA_p3_resp [3]
expxcue_int <- exp_bay_ANOVA_p3_resp [10] / exp_bay_ANOVA_p3_resp [6]
expxcuexblock_int <- exp_bay_ANOVA_p3_resp [18] / exp_bay_ANOVA_p3_resp [17]

```
In phase 3, there were no significant effects of the experiment or any of the interactions with that effect (Exp: `r apa(exp_c_ANOVA_p3_resp, effect = "exp_code", format = "rmarkdown")`, ExpxBlocks: `r apa(exp_c_ANOVA_p3_resp, effect = "exp_code:twoblocks", format = "rmarkdown")`, ExpxCue: `r apa(exp_c_ANOVA_p3_resp, effect = "exp_code:cue_type", format = "rmarkdown")`, ExpxBlocksxCue `r apa(exp_c_ANOVA_p3_resp, effect = "exp_code:twoblocks:cue_type", format = "rmarkdown")`). Bayesian analysis yielded moderate evidence for the null hypothesis regarding the main effect and the ExpxCue interaction (`r report_BF_and_error(exp_bay_ANOVA_p3_resp[1])`; `r report_BF_and_error(expxcue_int[1])`), and very strong evidence for the null hypothesis in the ExpxBlocks and ExpxBlocksxCue interactions (`r report_BF_and_error(expxblock_int[1])`; `r report_BF_and_error(expxcuexblock_int[1])`). Given that the effect of the experiment did not seem to have a significant effect on the results, they were re-analysed without including the experiment as a factor. Due to this evidence, the effects of the experiment are removed from the following analyses.

```{r, include = FALSE}
#prepare ANOVA phase 3
response_phase3 <- phase3 %>%
  group_by (pNum, block_real, cue_type) %>%
  summarise(mean_response = mean(prob_response, na.rm = TRUE))
response_phase3$block_real <- factor(response_phase3$block_real)
response_phase3$cue_type <- factor(response_phase3$cue_type)
response_phase3$pNum <- factor(response_phase3$pNum)
ANOVA_p3_resp <- aov_car(formula = mean_response ~ Error(pNum/block_real*cue_type), data = response_phase3)
bay_ANOVA_p3_resp <- anovaBF(formula = mean_response ~ block_real*cue_type + pNum,
        data = data.frame(response_phase3),
        whichRandom = "pNum")
bay_ANOVA_p3_int <- bay_ANOVA_p3_resp[4]/bay_ANOVA_p3_resp[3]
```
A within-subject ANOVA for phase 3 yielded significant differences for all effects, being the evidence very strong for both the blocks and the cue, but moderate in favor of the null for the interaction (Block: `r apa(ANOVA_p3_resp, effect = "block_real")`, `r report_BF_and_error(bay_ANOVA_p3_resp[1])`; Cue: `r apa(ANOVA_p3_resp, effect = "cue_type")`, `r report_BF_and_error(bay_ANOVA_p3_resp[2])`; interaction: `r apa(ANOVA_p3_resp, effect = "block_real:cue_type")`, `r report_BF_and_error(bay_ANOVA_p3_int[1])` ). This indicates that all subjects improved their performance as training progressed, and that accuracy was better for certain than uncertain cues, especially at the end of the experiment.

## Test phase

In the figure below, it can be seen that the memory score was the highest for the certain predictive cues, followed by the uncertain non predictive cues, then uncertain predictive cues, and finally, the certain non-predictive cues had the lowest memory score, but the differences were very subtle.

```{r}
#prepare data
Mmem_test <- merged_test_data %>%
  group_by(cue_type) %>%
  summarise(mean_mem_score = mean(mem_score, na.rm = TRUE), 
            sd_mem_score = sd(mem_score, na.rm = TRUE)/sqrt(length(mem_score)))

#plot in a histogram
ggplot(data = Mmem_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_mem_score)) +
  geom_errorbar(aes(x = cue_type, y= mean_mem_score, ymin = mean_mem_score - sd_mem_score, ymax = mean_mem_score + sd_mem_score)) +
  coord_cartesian(ylim = c(0, 10))+
  scale_x_discrete (name = "Type of cue") +
  scale_y_continuous(name = "Memory score") +
  labs(title = "Figure 2", subtitle = "Mean memory score for each type of cue in test phase")
```

```{r, include = FALSE}
#The factors would be the type of cue and the participant, the DV being the memory score. Also, as there are various scores for each cue I would just make a mean for them. 
merged_test_data <-  mutate(merged_test_data, 
               certainty = case_when(cue_type == "C_NP" | cue_type == "C_P" ~ "certain",
                                    cue_type == "U_NP" | cue_type == "U_P" ~ "uncertain"),
               predictiveness = case_when(cue_type == "U_P" | cue_type == "C_P" ~ "predictive",
                                    cue_type == "U_NP" | cue_type == "C_NP" ~ "nonpreditive"))
mem_mean_parti <- merged_test_data %>%
  group_by (exp_code, pNum, certainty, predictiveness) %>%
  summarise(mem_score = mean(mem_score, na.rm = TRUE))
#now factorize the IV
mem_mean_parti$exp_code <- factor(mem_mean_parti$exp_code)
mem_mean_parti$pNum <- factor(mem_mean_parti$pNum)
mem_mean_parti$certainty <- factor(mem_mean_parti$certainty)
mem_mean_parti$predictiveness <- factor(mem_mean_parti$predictiveness)
#ANOVA one between subjects factor (cue_type) on DV mem_score
exp_mem_score_test_ANOVA <- aov_car(formula = mem_score ~ exp_code + Error(pNum/certainty*predictiveness), data = mem_mean_parti)
exp_b_mem_score_AVOVA <- anovaBF(formula = mem_score ~ exp_code*certainty*predictiveness + pNum,
        data = data.frame(mem_mean_parti),
        whichRandom = "pNum")
# Calculate interaction Bayes Factor
exp_b_mem_score_AVOVA[4] / exp_b_mem_score_AVOVA[3]
exp_b_mem_score_AVOVA[10] / exp_b_mem_score_AVOVA[6]
exp_b_mem_score_AVOVA[18] / exp_b_mem_score_AVOVA[17]
```

In the test stage, nor the main effect of the experiment nor any of its interactions were significant (Exp: `r apa(exp_mem_score_test_ANOVA, effect = "exp_code", format = "rmarkdown")`, ExpxCertainty: `r apa(exp_mem_score_test_ANOVA, effect = "exp_code:certainty", format = "rmarkdown")`, ExpxPredictiveness: `r apa(exp_mem_score_test_ANOVA, effect = "exp_code:predictiveness", format = "rmarkdown")`, ExpxCertaintyxPredicitveness: `r apa(exp_mem_score_test_ANOVA, effect = "exp_code:certainty:predictiveness", format = "rmarkdown")`). The evidence for a null effect of the effect of the experiment and its interactions with certainty and with predictiveness was moderate (Exp: *BF* = 0.2973762 ±9.06%, ExpxCertainty: *BF* = 0.2352929 ±3.44%, ExpxPredictiveness: *BF* = 0.2306399 ±4.19%), whereas regarding the threeway interaction there was only anecdotal evidence for the null hypothesis (ExpxCertaintyxPredictiveness: *BF* = 0.4520292 ±20.98%).

```{r, include = FALSE}
mem_score_test_ANOVA <- aov_car(formula = mem_score ~ Error(pNum/certainty*predictiveness), data = mem_mean_parti)
b_mem_score_AVOVA <- anovaBF(formula = mem_score ~ certainty*predictiveness + pNum,
        data = data.frame(mem_mean_parti),
        whichRandom = "pNum")
# Calculate interaction Bayes Factor
b_mem_score_AVOVA[4] / b_mem_score_AVOVA[3]

```

When the analysis was repeated without taking into account the effect of the experiment, no significant main effects nor interaction were found(Certainty: `r apa(mem_score_test_ANOVA, effect = "certainty", format = "rmarkdown")`, Predictiveness: `r apa(mem_score_test_ANOVA, effect = "predictiveness", format = "rmarkdown")`, CertaintyxPredicitveness: `r apa(exp_mem_score_test_ANOVA, effect = "certainty:predictiveness", format = "rmarkdown")`). However, the evidence in favor of the null hypothesis for both the main effect of certainty and predictiveness was moderate (*BF* = 0.1666221 ±0.9%, *BF* = 0.1786582 ±1.18%), being the evidence for the null effect of the interaction anecdotal (*BF* = 0.6109978 ±2.81%).

Let's analyse only with the correct responses in the memory score.
```{r}
c_Mmem_test <- filter(merged_test_data, mem_score > -1) %>%
  group_by(cue_type) %>%
  summarise(mean_mem_score = mean(mem_score, na.rm = TRUE), 
           sd_mem_score = sd(mem_score, na.rm = TRUE)/sqrt(length(mem_score)))
ggplot(data = c_Mmem_test) +
  geom_col(mapping = aes(x = cue_type, y = mean_mem_score)) +
  geom_errorbar(aes(x = cue_type, y= mean_mem_score, ymin = mean_mem_score - sd_mem_score, ymax = mean_mem_score + sd_mem_score)) +
  coord_cartesian(ylim = c(0, 10))+
  scale_x_discrete (name = "Type of cue") +
  scale_y_continuous(name = "Positive memory score") +
  labs(title = "Figure 2", subtitle = "Mean memory score for each type of cue in test phase for correct answers")

#Analysis
c_mem_mean_parti <- filter(merged_test_data, acc == 1) %>%
  group_by (pNum, certainty, predictiveness) %>%
  summarise(mem_score = mean(mem_score, na.rm = TRUE))
#now factorize the IV
c_mem_mean_parti$pNum <- factor(c_mem_mean_parti$pNum)
c_mem_mean_parti$certainty <- factor(c_mem_mean_parti$certainty)
c_mem_mean_parti$predictiveness <- factor(c_mem_mean_parti$predictiveness)
#ANOVA one between subjects factor (cue_type) on DV mem_score
c_mem_score_test_ANOVA <- aov_car(formula = mem_score ~ Error(pNum/certainty*predictiveness), data = c_mem_mean_parti)
b_mem_score_AVOVA <- anovaBF(formula = mem_score ~ certainty*predictiveness + pNum,
        data = data.frame(c_mem_mean_parti),
        whichRandom = "pNum")
# Calculate interaction Bayes Factor
b_mem_score_AVOVA[4] / b_mem_score_AVOVA[3]
```
Again, no significant effects. Anecdotal null bayesian evidence for the main effects, anecdotal bayesian for the interaction. 

```{r}
#progression
merged_test_data <- mutate(merged_test_data, 
               presentation = case_when(trial_number <= 8 ~ "first",
                                        trial_number >= 9 ~ "second"))
merged_test_data <-  filter(merged_test_data, acc == 1)
 
test_progression <- merged_test_data %>%
  group_by(cue_type, presentation) %>%
  summarise(mean_mem_score = mean(mem_score, na.rm = TRUE), 
            sd_mem_score = sd(mem_score, na.rm = TRUE)/sqrt(length(mem_score)))

#plot in a histogram
ggplot(test_progression) +
  geom_col( mapping = aes(x = cue_type, fill = presentation, y = mean_mem_score), position = "dodge") +
  #facet_wrap(~ presentation)+
  #geom_errorbar(aes(x = cue_type, fill = presentation, y = mean_mem_score, ymin = mean_mem_score - sd_mem_score, ymax = mean_mem_score + sd_mem_score)) +
  coord_cartesian(ylim = c(0, 10))+
  scale_x_discrete (name = "Type of cue") +
  scale_y_continuous(name = "Memory score") +
  labs(title = "Figure 2", subtitle = "Mean memory score for each type of cue in test phase")

#analyse
test_progression_parti <- merged_test_data %>%
  group_by(pNum, certainty, predictiveness, presentation) %>%
  summarise(mean_mem_score = mean(mem_score, na.rm = TRUE))
test_progression_parti$pNum <- factor(test_progression_parti$pNum)
test_progression_parti$certainty <- factor(test_progression_parti$certainty)
test_progression_parti$predictiveness <- factor(test_progression_parti$predictiveness)
test_progression_parti$presentation <- factor(test_progression_parti$presentation)
#ANOVA one between subjects factor (cue_type) on DV mem_score
test_progression_ANOVA <- aov_car(formula = mean_mem_score ~ Error(pNum/certainty*predictiveness*presentation), data = test_progression_parti)
b_mem_score_AVOVA <- anovaBF(formula = mean_mem_score ~ certainty*predictiveness*presentation + pNum,
        data = data.frame(test_progression_parti),
        whichRandom = "pNum")
# Calculate interaction Bayes Factor
b_mem_score_AVOVA[4] / b_mem_score_AVOVA[3]
b_mem_score_AVOVA[10] / b_mem_score_AVOVA[6]
b_mem_score_AVOVA[18] / b_mem_score_AVOVA[17]
```

```{r}
library(pwr)
> ?`pwr-package`
```

